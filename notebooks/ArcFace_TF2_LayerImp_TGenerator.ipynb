{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArcFace_TF2_LayerImp_TGenerator",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1SyTe7qRpZW9cETfve9E2UigOr8yZip1L",
      "authorship_tag": "ABX9TyN4HzN4Oyc+BjjFryct7Q4t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dakilaledesma/arcface-classifier/blob/main/notebooks/ArcFace_TF2_LayerImp_TGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "! unzip -q /content/drive/MyDrive/UNC/H2022/orchidaceae_train.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu4GFI1sPLlA",
        "outputId": "c36066b7-620f-4ed7-d89c-f6946e24fb0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 122 ms, sys: 30.1 ms, total: 153 ms\n",
            "Wall time: 21.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNMk9tixPI0v",
        "outputId": "027e248f-e2e6-4a68-95d7-d90e6de5e1e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 14.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U tensorflow-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "355uor5m4Mas",
        "outputId": "ba8cdb97-ff22-4106-96e1-cb02580795ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 4.9 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 62.2 MB/s \n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.26.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.47.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 93.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.3.7)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Dense, Concatenate, Flatten, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from glob import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "IZXvk2iKNEtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V5aOhxOL9yM"
      },
      "outputs": [],
      "source": [
        "# From https://github.com/ozora-ogino/asoftmax-tf/blob/main/asoftmax.py\n",
        "class ASoftmax(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_classes=10,\n",
        "        scale=30.0,\n",
        "        margin=0.50,\n",
        "        regularizer=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        \"\"\"[ASoftmax]\n",
        "        Args:\n",
        "            n_classes (int, optional): Number of class. Defaults to 10.\n",
        "            scale (float, optional): Float variable for scaling. Defaults to 30.0.\n",
        "            margin (float, optional): Float variable of margin. Defaults to 0.50.\n",
        "            regularizer (function, optional): keras.regularizers. Defaults to None.\n",
        "        \"\"\"\n",
        "\n",
        "        super(ASoftmax, self).__init__(**kwargs)\n",
        "        self.n_classes = n_classes\n",
        "        self.scale = scale\n",
        "        self.margin = margin\n",
        "        self.regularizer = regularizers.get(regularizer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ASoftmax, self).build(input_shape[0])\n",
        "        self.W = self.add_weight(\n",
        "            name=\"W\",\n",
        "            shape=(input_shape[0][-1], self.n_classes),\n",
        "            initializer=\"glorot_uniform\",\n",
        "            trainable=True,\n",
        "            regularizer=self.regularizer,\n",
        "        )\n",
        "\n",
        "    def _train_op(self, inputs):\n",
        "        x, y = inputs\n",
        "\n",
        "        # Normalization\n",
        "        x = tf.nn.l2_normalize(x, axis=1)\n",
        "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
        "\n",
        "        # Dot product\n",
        "        logits = x @ W\n",
        "\n",
        "        # Add margin and clip logits to prevent zero division when backward\n",
        "        theta = tf.acos(K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n",
        "        target_logits = tf.cos(theta + self.margin)\n",
        "        logits = logits * (1 - y) + target_logits * y\n",
        "\n",
        "        # Rescale the feature\n",
        "        logits *= self.scale\n",
        "        out = tf.nn.softmax(logits)\n",
        "        return out\n",
        "\n",
        "    def _predict_op(self, inputs):\n",
        "        # Normalization\n",
        "        x = tf.nn.l2_normalize(inputs, axis=1)\n",
        "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
        "        logits = x @ W\n",
        "        out = tf.nn.softmax(logits)\n",
        "        return out\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        if training:\n",
        "            out = self._train_op(inputs)\n",
        "        else:\n",
        "            out = self._predict_op(inputs)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 300"
      ],
      "metadata": {
        "id": "j3v563jzRMX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = image.ImageDataGenerator(\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      fill_mode='nearest',\n",
        "      rescale=1./255)"
      ],
      "metadata": {
        "id": "xR9M4qw0nv3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/59921314/multi-input-model-with-flow-from-directory\n",
        "def af_generator(datagen, directory, target_size, batch_size):\n",
        "  gen = train_datagen.flow_from_directory(\n",
        "        directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "  \n",
        "  while True:\n",
        "    K.set_learning_phase(1)\n",
        "    x = gen.next()\n",
        "    yield [x[0], x[1]], x[1]"
      ],
      "metadata": {
        "id": "NCYA8ivituEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = af_generator(\n",
        "    train_datagen,\n",
        "    'orchidaceae_train/',\n",
        "    (224, 224),\n",
        "    64)"
      ],
      "metadata": {
        "id": "S03N1ONfpyly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = train_datagen.flow_from_directory(\n",
        "    'orchidaceae_train/',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "id": "QlQKLd9Yyw8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AFModel(Model):\n",
        "  def __init__(self, num_classes=300, weight_decay=1e-4):\n",
        "        super(AFModel, self).__init__()\n",
        "        self.label_input = Input(shape=(num_classes,))\n",
        "        self.backbone = ResNet50(\n",
        "            input_shape=(224, 224, 3), \n",
        "            weights='imagenet', \n",
        "            include_top=False)\n",
        "        self.layer_1 = GlobalAveragePooling2D()\n",
        "        self.layer_2 = Dense(512, activation='relu')\n",
        "\n",
        "        self.out = ASoftmax(\n",
        "            n_classes=num_classes,\n",
        "            regularizer=regularizers.l2(weight_decay),\n",
        "        )\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "      print(training)\n",
        "      if training:\n",
        "          x, y = x[0], x[1]\n",
        "      x = self.backbone(x)\n",
        "      x = self.layer_1(x)\n",
        "      x = self.layer_2(x)\n",
        "\n",
        "      if training:\n",
        "          # When training, you need to pass label to ASoftmax\n",
        "          out = self.out([x, y])\n",
        "      else:\n",
        "          out = self.out(x)\n",
        "      return out\n",
        "\n",
        "model = AFModel()\n",
        "\n",
        "opt = tfa.optimizers.AdaBelief(learning_rate=1e-3)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "      x=val_generator,\n",
        "      validation_data=val_generator,\n",
        "      epochs=100,\n",
        "      verbose=2)"
      ],
      "metadata": {
        "id": "Wcf78rlfNCbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "! unzip -q /content/drive/MyDrive/UNC/H2022/orchidaceae_test.zip -d /content/"
      ],
      "metadata": {
        "id": "fMRw_iR4S9FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = []\n",
        "test_y = []\n",
        "orc_test = sorted(glob(\"orchidaceae_test/**/*.*\", recursive=True))\n",
        "for fn in tqdm(orc_test, total=len(list(orc_test))):\n",
        "  bn =  os.path.basename(fn)\n",
        "  cat = cat_to_int[fn.split(\"/\")[-2]]\n",
        "\n",
        "  img = image.load_img(fn, target_size=(224, 224))\n",
        "  x = image.img_to_array(img)\n",
        "  x = preprocess_input(x)\n",
        "  test_x.append(x)\n",
        "\n",
        "  test_y.append(cat)"
      ],
      "metadata": {
        "id": "U9NaToo2wHaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = np.array(test_x)"
      ],
      "metadata": {
        "id": "aOwn-kZG0LwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for idx, im in tqdm(enumerate(test_x), total=len(test_x)):\n",
        "  im = np.expand_dims(im, 0)\n",
        "  pred = np.argmax(model(im))\n",
        "  preds.append(pred)"
      ],
      "metadata": {
        "id": "i4vArwUX0239"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on training data\n",
        "print(accuracy_score(test_y, preds))"
      ],
      "metadata": {
        "id": "DrZDkCzb1fXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on test data\n",
        "print(accuracy_score(test_y, preds))"
      ],
      "metadata": {
        "id": "dwdj1xst4dmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"arcface_orcl_1_max\")"
      ],
      "metadata": {
        "id": "f1EaXfPv48sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SxKdjll9BlDl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}